{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seat belt, seatbelt\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import EfficientNetImageProcessor, EfficientNetForImageClassification\n",
    "from PIL import Image\n",
    "import math\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "from distracted.dataset_loader import dataset_loader\n",
    "\n",
    "image = Image.open('data/imgs/train/c0/img_34.jpg')\n",
    "\n",
    "preprocessor = EfficientNetImageProcessor.from_pretrained(\"google/efficientnet-b7\")\n",
    "model = EfficientNetForImageClassification.from_pretrained(\"google/efficientnet-b7\")\n",
    "\n",
    "inputs = preprocessor(image, return_tensors=\"pt\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(**inputs).logits\n",
    "\n",
    "# model predicts one of the 1000 ImageNet classes\n",
    "predicted_label = logits.argmax(-1).item()\n",
    "print(model.config.id2label[predicted_label]),\n",
    "# device = torch.device(\"cuda\")\n",
    "device = torch.device('cpu')\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.modeling_outputs.ImageClassifierOutputWithNoAttention"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model(**inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset_loader()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Link to guide for adding additional layers to pretrained model](https://medium.com/analytics-vidhya/how-to-add-additional-layers-in-a-pre-trained-model-using-pytorch-5627002c75a5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EfficientNet_Adapter_Finetuning(EfficientNetForImageClassification):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(self).__init__()\n",
    "        self.model = EfficientNetForImageClassification.from_pretrained(\"google/efficientnet-b7\")\n",
    "\n",
    "    def forward(self, pixel_values: torch.FloatTensor = None,): # Add input stuff\n",
    "        # Get output for EfficientNetModel then do EfficientNetForImageClassification part of forward()\n",
    "        # Should have self.embeddings from EfficientNetModel which will probably not need to be retrained\n",
    "        embedding_output = self.embeddings(pixel_values)\n",
    "\n",
    "        # self.encoder is likely what needs to be finetuned\n",
    "        # Encoder is EfficentNetEncoder\n",
    "        # Forward pass of Encoder loops through blocks and updates hidden_states\n",
    "        # Endcoder with potential edits looks like following:\n",
    "\n",
    "        # for block,adapter in (self.blocks,self.adapters):\n",
    "        #     hidden_states = block(hidden_states)\n",
    "        #     hidden_states = adapter(hidden_states)\n",
    "\n",
    "        # hidden_states = self.top_conv(hidden_states)\n",
    "        # hidden_states = self.top_bn(hidden_states)\n",
    "        # hidden_states = self.top_activation(hidden_states)\n",
    "        \n",
    "        # Idea is to add adapter layer after each loop \n",
    "\n",
    "        # Maybe Make EfficinetNet_Adapter_Encoder model then change self.model.something.encoder to this new one\n",
    "        # Can initialize it with pretrained so self.blocks is the same\n",
    "\n",
    "\n",
    "        encoder_outputs = self.encoder(\n",
    "            embedding_output,\n",
    "            output_hidden_states=self.config.output_hidden_states,\n",
    "            )\n",
    "\n",
    "        # EfficientNetForImageClassification forward takes output of EfficientNetModel and does the following:\n",
    "        # outputs = self.efficientnet(pixel_values, output_hidden_states=output_hidden_states, return_dict=return_dict)\n",
    "\n",
    "        # pooled_output = outputs.pooler_output if return_dict else outputs[1]\n",
    "        # pooled_output = self.dropout(pooled_output)\n",
    "        # logits = self.classifier(pooled_output)\n",
    "        # logits = self.classifier_act(logits)\n",
    "\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Paper on adapters](https://arxiv.org/pdf/1803.10082.pdf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_instance = model.efficientnet.encoder\n",
    "encoder_class = encoder_instance.__class__\n",
    "# config = model.config\n",
    "\n",
    "# block_input = torch.randn(1,64,300,300)\n",
    "# encoder_block_output_class = encoder_instance.blocks[0](block_input).__class__\n",
    "# print(encoder_block_output_class)\n",
    "\n",
    "# Following two functions taken from modeling_efficientnet.py\n",
    "def round_repeats(repeats,depth_coefficient):\n",
    "            # Round number of block repeats based on depth multiplier.\n",
    "            return int(math.ceil(depth_coefficient * repeats))\n",
    "def round_filters(config, num_channels: int):\n",
    "    r\"\"\"\n",
    "    Round number of filters based on depth multiplier.\n",
    "    \"\"\"\n",
    "    divisor = config.depth_divisor\n",
    "    num_channels *= config.width_coefficient\n",
    "    new_dim = max(divisor, int(num_channels + divisor / 2) // divisor * divisor)\n",
    "\n",
    "    # Make sure that round down does not go down by more than 10%.\n",
    "    if new_dim < 0.9 * num_channels:\n",
    "        new_dim += divisor\n",
    "\n",
    "    return int(new_dim)\n",
    "\n",
    "\n",
    "\n",
    "class EfficientNetAdapterEncoding(encoder_class):\n",
    "    def __init__(self, model):\n",
    "        encoder_instance = model.efficientnet.encoder\n",
    "        config = model.config\n",
    "        super().__init__(config)\n",
    "    \n",
    "        self.blocks = encoder_instance.blocks\n",
    "        self.top_conv = encoder_instance.top_conv\n",
    "        self.top_bn = encoder_instance.top_bn\n",
    "        self.top_activation = encoder_instance.top_activation\n",
    "        self.adapters = []\n",
    "\n",
    "        \n",
    "\n",
    "        num_base_blocks = len(config.in_channels)\n",
    "        adapter_dimensions = []\n",
    "        block_dimensions = []\n",
    "        for i in range(num_base_blocks):\n",
    "            block_out_dim = round_filters(config,config.out_channels[i])\n",
    "            block_in_dim = round_filters(config,config.in_channels[i]) \n",
    "            for _ in range(round_repeats(config.num_block_repeats[i],config.depth_coefficient)):\n",
    "                block_dimensions.append((block_in_dim,block_out_dim))\n",
    "        for j in range(len(block_dimensions)-1):\n",
    "             adapter_dimension_input = block_dimensions[j][1] # output of previous block\n",
    "             adapter_dimension_output = block_dimensions[j+1][0] # input of next block\n",
    "             adapter_dimensions.append((adapter_dimension_input,adapter_dimension_output))\n",
    "        last_adapter_dimension = block_dimensions[-1][1]\n",
    "        adapter_dimensions.append((last_adapter_dimension,last_adapter_dimension))\n",
    "\n",
    "        for adapter_dimension in adapter_dimensions:\n",
    "             self.adapters.append(nn.Linear(*adapter_dimension))\n",
    "        # Wrong dimensions\n",
    "        # Also wayyyyyyyyyyyyyyyy too many parameters if right dimensions.....\n",
    "        # Don't use Linear\n",
    "\n",
    "\n",
    "    def forward(self,\n",
    "                hidden_states,\n",
    "                output_hidden_states = False,\n",
    "                return_dict = True):\n",
    "        \n",
    "        for block,adapter in zip(self.blocks,self.adapters):\n",
    "            hidden_states = block(hidden_states)\n",
    "            hidden_states = adapter(hidden_states)\n",
    "        \n",
    "        hidden_states = self.top_conv(hidden_states)\n",
    "        hidden_states = self.top_bn(hidden_states)\n",
    "        hidden_states = self.top_activation(hidden_states)\n",
    "            \n",
    "        return (hidden_states,None) # Should work as forward pass just takes encoder_output[0]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "adapter_encoding = EfficientNetAdapterEncoding(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder_instance.blocks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_input = torch.randn(1,64,300,300)\n",
    "encoder_block_output = encoder_instance.blocks[0](block_input)\n",
    "print(encoder_block_output.size())\n",
    "print(adapter_encoding.adapters[0])\n",
    "adapter_encoding.adapters[0](encoder_block_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_instance = model.efficientnet.encoder\n",
    "encoder_instance.to(device)\n",
    "# adapter_encoding.to(\"cpu\")\n",
    "from torchsummary import summary\n",
    "# use this later for checking trainable params etc\n",
    "# block 0 has 64, 300, 300\n",
    "block = encoder_instance.blocks[-1]\n",
    "block.to(device)\n",
    "summary(block,input_size=(640,300,300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 300, 300])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.efficientnet.embeddings(**inputs).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through named_parameters and set adapters to True and everything else to False?\n",
    "# for name,para in model.named_parameters():\n",
    "#     print(name, para.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.config"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
